{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d2b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_score, accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pmdarima as pm\n",
    "import statsmodels.api as api\n",
    "from scipy.stats import norm\n",
    "\n",
    "from utils import grab_data, import_wl_data, import_ph_data, import_ec_data, unit_scale, remove_outliers\n",
    "from models.data_validation import ReportErrors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e8a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in metadata csv's #\n",
    "depth120d = pd.read_csv(\"data/metadata - 120d.csv\")\n",
    "pH_meta = pd.read_csv(\"data/wq_metadata - pH.csv\")\n",
    "ec_meta = pd.read_csv(\"data/wq_metadata - EC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3618c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility functions ###\n",
    "def add_derv(df, tol = 0.00001):\n",
    "    df = df.copy()\n",
    "    df['smoothed'] = df['Value'].rolling(window=6*8, min_periods=1, center=True).mean()\n",
    "    df['mean diff'] = df['smoothed'].diff(1).fillna(0) / df.index.to_series().diff(periods=1).dt.seconds #careful for non-USGS data\n",
    "    df = df.drop(df[df['mean diff'] < -1e308]['mean diff'].index)\n",
    "    df_down = df[df['mean diff'] < -1*tol]\n",
    "    df_up = df[df['mean diff'] >= tol]\n",
    "    \n",
    "    return df, df_down, df_up\n",
    "\n",
    "def cut_ends(df): # removes the 1st and 99th percentile value measurements to ensure no outliers\n",
    "    try:\n",
    "        q1, q99 = df['Value'].quantile([0.01, 0.99])\n",
    "        a = df.copy()\n",
    "        if len(df[df['Value']<q1]) < 0.02*len(df): \n",
    "            a = df[df['Value']>q1]\n",
    "        if len(a[a['Value']>q99]) < 0.02*len(df):\n",
    "            a = a[a['Value']<q99]\n",
    "        return a\n",
    "    except:\n",
    "        return df\n",
    "\n",
    "### Rule-based tests ###\n",
    "def flag_depth_errors(df, offset):\n",
    "    \n",
    "    flag = False\n",
    "    df, neg_flag, sat_flag = ReportErrors.detect_out_of_range(df, offset)\n",
    "    df, und_flag = ReportErrors.detect_underliers(df)\n",
    "    \n",
    "    if neg_flag:\n",
    "        flag = True\n",
    "    if sat_flag:\n",
    "        flag = True\n",
    "    if und_flag:\n",
    "        flag = True\n",
    "    \n",
    "    return df, flag\n",
    "\n",
    "def flag_ph_errors(df, tol=25):\n",
    "    \n",
    "    flag = False\n",
    "    initial_len = len(df)\n",
    "    \n",
    "    df = df.drop(df[df['Value']< 6.5].index)\n",
    "    df = df.drop(df[df['Value'] > 11.0].index)\n",
    "    \n",
    "    if len(df) < initial_len - tol:\n",
    "        flag = True\n",
    "    \n",
    "    return df, flag\n",
    "\n",
    "def flag_ec_errors(df, tol=25):\n",
    "    \n",
    "    flag = False\n",
    "    \n",
    "    return df, flag\n",
    "\n",
    "### Grid-search to optimize binary classification model ###\n",
    "def svm_classification(data, y, scoring = 'accuracy'):\n",
    "    params = [{'kernel':['linear', 'rbf', 'poly'], 'C':[0.1, 1, 10, 100]}]\n",
    "    clf_pipe = SVC()\n",
    "    gs_clf = GridSearchCV(clf_pipe, param_grid=params, scoring=scoring, cv=5)\n",
    "    gs_clf.fit(data, y)\n",
    "    return gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ca2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_depth(metadata, nbins=10, cv_k=5, dim=2, tol=1e-4, model='svm', scoring = 'accuracy'):\n",
    "    '''\n",
    "    Function accepts a metadata file and returns a binary classification prediction.\n",
    "    Arguments\n",
    "        - metadata: the metadata file (see data/ folder for examples)\n",
    "        - nbins: an int or 2-value list defining the number of bins to use in the histogram\n",
    "        - cv_k: the number of folds to use in the cross validation\n",
    "        - dim: 1 (classify on value distributions) or 2 (classify on phase portraits)\n",
    "        - tol: tolerance used in identifying which parts of the signal are in recession\n",
    "        - model: the binary classification model used\n",
    "        - scoring: the metric optimized on in the grid-search\n",
    "    Returns: \n",
    "        - preditcted labels for every sample\n",
    "        - the true value labels for every sample\n",
    "    '''\n",
    "    df = metadata.copy()\n",
    "    df['flag'] = np.zeros(len(df)) \n",
    "    class_X = [] # list of X for classification\n",
    "    class_i = [] # list of indicies to run classification on\n",
    "    class_y = [] # list of true y for classification\n",
    "        \n",
    "    for row, col in df.iterrows():\n",
    "        data = import_wl_data(node_id=col['Node ID'], site_id=col['Site ID']) # import timeseries\n",
    "        data = data[col['start']:col['end']] # isolate the relevant subset\n",
    "        label = col['Clean'] # get the true label value\n",
    "        offset = col['Offset (mm)'] # get the offset (calibration parameter for water level sensor data)\n",
    "        \n",
    "        if len(data) == 0: # if theres no measurements, flag the timeseries\n",
    "            df['flag'].iloc[row] = 1 \n",
    "        else:\n",
    "            data, flag = flag_depth_errors(data, offset) # this function needs to be specified to type of sensor\n",
    "                \n",
    "            if flag:\n",
    "                df['flag'].iloc[row] = 1 # exclude any samples that were flagged by the rule-based tests\n",
    "            else:\n",
    "                depth, depth_down, depth_up = add_derv(data, tol=tol) # calculate the derivative\n",
    "                if len(depth_down) == 0: # if no part of the timeseries is in recession, flag the sample\n",
    "                    df['flag'].iloc[row] = 1\n",
    "                else:\n",
    "                    X = np.array(depth_down[['Value', 'mean diff']]) # calculate the phase portrait\n",
    "                    if dim == 2:\n",
    "                        h, x_e, y_e = np.histogram2d(X[:,0], X[:,1], nbins)\n",
    "                    else:\n",
    "                        h, x_e = np.histogram(X[:,0], nbins)\n",
    "                    h = np.reshape(h, (-1,1))\n",
    "                    mm = make_pipeline(StandardScaler(), MinMaxScaler()) # normalize the histogram\n",
    "                    h = mm.fit_transform(h)\n",
    "                    class_i.append(row) \n",
    "                    class_X.append(np.ndarray.flatten(h))\n",
    "                    class_y.append(label)\n",
    "    \n",
    "    y = np.array(class_y) # prepare the classificiation dataset (all of the samples that were not flagged)\n",
    "    X = np.array(class_X)\n",
    "\n",
    "    # optimizes model parameters based on a gridsearch\n",
    "    if model == 'mlp':\n",
    "        best_params = mlp_classification(X, y, scoring=scoring)\n",
    "        m = MLPClassifier(alpha=best_params['alpha'], \n",
    "                            random_state=best_params['random_state'],\n",
    "                            hidden_layer_sizes = best_params['hidden_layer_sizes'],)\n",
    "    elif model == 'svm':\n",
    "        best_params = svm_classification(X, y, scoring=scoring) \n",
    "        m = SVC(kernel=best_params['kernel'], C=best_params['C'])\n",
    "    elif model == 'nb':\n",
    "        best_params = nb_classification(X, y, scoring=scoring)\n",
    "        m = GaussianNB(var_smoothing=best_params['var_smoothing'])\n",
    "    elif model == 'ada':\n",
    "        best_params = ada_classification(X, y, scoring=scoring)\n",
    "        m = AdaBoostClassifier(n_estimators=best_params['n_estimators'])\n",
    "    elif model == 'gp':\n",
    "        best_params = gp_classification(X, y, scoring=scoring)\n",
    "        m = GaussianProcessClassifier(kernel=best_params['kernel'])\n",
    "    elif model == 'knn':\n",
    "        best_params = knn_classification(X, y, scoring=scoring)\n",
    "        m = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'])\n",
    "    else:\n",
    "        return 0, -1\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=cv_k) # use cross validation to get a prediction for every sample\n",
    "\n",
    "    classified = pd.DataFrame({'y': y, 'prediction': y_pred})\n",
    "    classified.index = class_i\n",
    "    testdf = df[df['flag']==1]['Clean']\n",
    "        \n",
    "    flagged = pd.DataFrame({'y': testdf, 'prediction': np.zeros(len(testdf))})\n",
    "    \n",
    "    final_class = pd.concat([classified, flagged]) # re-combine the flagged and classified datasets\n",
    "    \n",
    "    return final_class['prediction'], final_class['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d7c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ph(metadata, nbins=10, cv_k = 5, dim=2, tol=1e-6, model='svm', scoring='accuracy'):\n",
    "    '''\n",
    "    Function accepts a metadata file and returns a binary classification prediction.\n",
    "    Arguments:\n",
    "        - metadata: the metadata file (see data/ folder for examples)\n",
    "        - nbins: an int or 2-value list defining the number of bins to use in the histogram\n",
    "        - cv_k: the number of folds to use in the cross validation\n",
    "        - dim: 1 (classify on value distributions) or 2 (classify on phase portraits)\n",
    "        - tol: tolerance used in identifying which parts of the signal are in recession\n",
    "        - model: the binary classification model used\n",
    "        - scoring: the metric optimized on in the grid-search\n",
    "    Returns: \n",
    "        - preditcted labels for every sample\n",
    "        - the true value labels for every sample\n",
    "    '''\n",
    "    y_predictions = np.zeros(len(metadata)) # define array of predictions\n",
    "    classification_i = [] # list of indicies to run classification on\n",
    "    classification_X = [] # list of X for classification\n",
    "    classification_y = [] # list of true y for classification\n",
    "    \n",
    "    for row, col in metadata.iterrows():\n",
    "        data = import_ph_data(col['node_id'], col['start'], col['end'])\n",
    "        label = col['clean']\n",
    "\n",
    "        data, flag = flag_ph_errors(data) # this function needs to be specified to type of sensor\n",
    "\n",
    "        if len(data) != 0: \n",
    "            if not flag:\n",
    "                if len(data) > 100: # for water quality data, trimming off the extreme value ends of the timeseries\n",
    "                    data = cut_ends(data) # improves classification by ensuring all outliers are removed\n",
    "                    \n",
    "                ph, ph_down, ph_up = add_derv(data, tol=tol)\n",
    "\n",
    "                if len(ph_down) != 0:\n",
    "                    X = np.array(ph_down[['Value', 'mean diff']])\n",
    "                    if dim ==2:\n",
    "                        h, x_e, y_e = np.histogram2d(X[:,0], X[:,1], nbins)\n",
    "                    else:\n",
    "                        h, x_e = np.histogram(X[:,0], nbins)\n",
    "                        \n",
    "                    h = np.reshape(h, (-1,1))\n",
    "                    mm = make_pipeline(StandardScaler(), MinMaxScaler())\n",
    "                    h = mm.fit_transform(h)\n",
    "\n",
    "                    classification_i.append(row)\n",
    "                    classification_X.append(np.ndarray.flatten(h))\n",
    "                    classification_y.append(label)\n",
    "    \n",
    "    X = np.array(classification_X)\n",
    "    y = np.array(classification_y)\n",
    "    \n",
    "    if model == 'mlp':\n",
    "        best_params = mlp_classification(X, y, scoring=scoring)\n",
    "        m = MLPClassifier(alpha=best_params['alpha'], \n",
    "                            random_state=best_params['random_state'],\n",
    "                            hidden_layer_sizes = best_params['hidden_layer_sizes'],)\n",
    "    elif model == 'svm':\n",
    "        best_params = svm_classification(X, y, scoring=scoring)\n",
    "        m = SVC(kernel=best_params['kernel'], C=best_params['C'])\n",
    "    elif model == 'nb':\n",
    "        best_params = nb_classification(X, y, scoring=scoring)\n",
    "        m = GaussianNB(var_smoothing=best_params['var_smoothing'])\n",
    "    elif model == 'ada':\n",
    "        best_params = ada_classification(X, y, scoring=scoring)\n",
    "        m = AdaBoostClassifier(n_estimators=best_params['n_estimators'])\n",
    "    elif model == 'gp':\n",
    "        best_params = gp_classification(X, y, scoring=scoring)\n",
    "        m = GaussianProcessClassifier(kernel=best_params['kernel'])\n",
    "    elif model == 'knn':\n",
    "        best_params = knn_classification(X, y, scoring=scoring)\n",
    "        m = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'])\n",
    "    else:\n",
    "        return 0, -1\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=cv_k)\n",
    "\n",
    "    for i in range(len(classification_i)):\n",
    "        y_predictions[classification_i[i]] = y_pred[i]\n",
    "    print(y_predictions)\n",
    "    return y_predictions, np.array(metadata['clean'])\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8c8a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ec(metadata, nbins=10, cv_k=5, dim=2, tol=1e-6, model='svm', scoring='accuracy'):\n",
    "    '''\n",
    "    Function accepts a metadata file and returns a binary classification prediction.\n",
    "    Arguments\n",
    "        - metadata: the metadata file (see data/ folder for examples)\n",
    "        - nbins: an int or 2-value list defining the number of bins to use in the histogram\n",
    "        - cv_k: the number of folds to use in the cross validation\n",
    "        - dim: 1 (classify on value distributions) or 2 (classify on phase portraits)\n",
    "        - tol: tolerance used in identifying which parts of the signal are in recession\n",
    "        - model: the binary classification model used\n",
    "        - scoring: the metric optimized on in the grid-search\n",
    "    Returns: \n",
    "        - preditcted labels for every sample\n",
    "        - the true value labels for every sample\n",
    "    '''\n",
    "    y_predictions = np.zeros(len(metadata)) # define array of predictions\n",
    "    classification_i = [] # list of indicies to run classification on\n",
    "    classification_X = [] # list of X for classification\n",
    "    classification_y = [] # list of true y for classification\n",
    "    \n",
    "    for row, col in metadata.iterrows():\n",
    "        data = import_ec_data(col['node_id'], col['start'], col['end'])\n",
    "        label = col['clean']\n",
    "\n",
    "        data, flag = flag_ec_errors(data) # this function needs to be specified to type of sensor\n",
    "\n",
    "        if len(data) != 0: \n",
    "            if not flag:\n",
    "                if len(data) > 100:\n",
    "                    data = cut_ends(data)\n",
    "                    \n",
    "                ec, ec_down, ec_up = add_derv(data, tol=tol)\n",
    "\n",
    "                if len(ec_down) != 0:\n",
    "                    X = np.array(ec_down[['Value', 'mean diff']])\n",
    "                    if dim ==2:\n",
    "                        h, x_e, y_e = np.histogram2d(X[:,0], X[:,1], nbins)\n",
    "                    else:\n",
    "                        h, x_e = np.histogram(X[:,0], nbins)\n",
    "                    h = np.reshape(h, (-1,1))\n",
    "\n",
    "                    mm = make_pipeline(StandardScaler(), MinMaxScaler())\n",
    "                    h = mm.fit_transform(h)\n",
    "\n",
    "                    classification_i.append(row)\n",
    "                    classification_X.append(np.ndarray.flatten(h))\n",
    "                    classification_y.append(label)\n",
    "    \n",
    "    \n",
    "    X = np.array(classification_X)\n",
    "    y = np.array(classification_y)\n",
    "    if model == 'mlp':\n",
    "        best_params = mlp_classification(X, y, scoring=scoring)\n",
    "        m = MLPClassifier(alpha=best_params['alpha'], \n",
    "                            random_state=best_params['random_state'],\n",
    "                            hidden_layer_sizes = best_params['hidden_layer_sizes'],)\n",
    "    elif model == 'svm':\n",
    "        best_params = svm_classification(X, y, scoring=scoring)\n",
    "        m = SVC(kernel=best_params['kernel'], C=best_params['C'])\n",
    "    elif model == 'nb':\n",
    "        best_params = nb_classification(X, y, scoring=scoring)\n",
    "        m = GaussianNB(var_smoothing=best_params['var_smoothing'])\n",
    "    elif model == 'ada':\n",
    "        best_params = ada_classification(X, y, scoring=scoring)\n",
    "        m = AdaBoostClassifier(n_estimators=best_params['n_estimators'])\n",
    "    elif model == 'gp':\n",
    "        best_params = gp_classification(X, y, scoring=scoring)\n",
    "        m = GaussianProcessClassifier(kernel=best_params['kernel'])\n",
    "    elif model == 'knn':\n",
    "        best_params = knn_classification(X, y, scoring=scoring)\n",
    "        m = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'])\n",
    "    else:\n",
    "        return 0, -1\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=cv_k)\n",
    "    \n",
    "    for i in range(len(classification_i)):\n",
    "        y_predictions[classification_i[i]] = y_pred[i]\n",
    "    \n",
    "    return y_predictions, np.array(metadata['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47d86a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_mean_check(metadata, dataset='wl', w='5D', nstd=2, pct_thrsh=0.05):\n",
    "    '''\n",
    "    Fits a moving average (MA) and moving stanrdard deviation to the time series to detect anomalies.\n",
    "    Arguments\n",
    "        - metadata: the metadata file (see data/ folder for examples)\n",
    "        - dataset: 'wl', 'pH', or 'ec', used to specify which import and flagging functions should be used\n",
    "        - w: window size, 'D' stands for days, used to specify the window size for the moving avg, std\n",
    "        - nstd: the number of standard deviations from the mean a point has to be to be considered anomalous\n",
    "        - pct_thrsh: the percentage of data that must be anomalous for a site to be classified as obstructed\n",
    "    '''\n",
    "    df = metadata.copy()\n",
    "    df['flag'] = np.zeros(len(df))\n",
    "    for row, col in df.iterrows():\n",
    "        if dataset == 'wl':\n",
    "            data = import_wl_data(node_id=col['Node ID'], site_id=col['Site ID'])\n",
    "            data = data[col['start']:col['end']]\n",
    "            offset = col['Offset (mm)']\n",
    "        elif dataset == 'pH':\n",
    "            data = import_ph_data(col['node_id'], col['start'], col['end'])\n",
    "        elif dataset == 'ec':\n",
    "            data = import_ec_data(col['node_id'], col['start'], col['end'])\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            df['flag'].iloc[row] = 1\n",
    "        else:\n",
    "            if dataset == 'wl':\n",
    "                data, flag = flag_depth_errors(data, offset)\n",
    "            elif dataset == 'pH':\n",
    "                data, flag = flag_ph_errors(data)\n",
    "            elif dataset == 'ec':\n",
    "                data, flag = flag_ec_errors(data)\n",
    "                \n",
    "            if flag:\n",
    "                df['flag'].iloc[row] = 1\n",
    "            else:\n",
    "                mean = data['Value'].rolling(window=w, min_periods=1, center=True).mean()\n",
    "                std = data['Value'].rolling(window=w, min_periods=1, center=True).std()\n",
    "                upper_thrsh = mean + nstd*std\n",
    "                lower_thrsh = mean - nstd*std\n",
    "                up_out = data[data['Value'] > upper_thrsh]\n",
    "                low_out = data[data['Value'] < lower_thrsh]\n",
    "                pct_out = len(up_out + low_out)/len(data)\n",
    "                if pct_out > pct_thrsh:\n",
    "                    df['flag'].iloc[row] = 1\n",
    "    y_pred = np.ones(len(df)) - df['flag']\n",
    "    \n",
    "    if dataset == 'wl':\n",
    "        return y_pred, df['Clean']\n",
    "    else:\n",
    "        return y_pred, df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a987fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arima_fit(data):\n",
    "    '''\n",
    "    Automatically tunes and fits an ARIMA model to a timeseries, returning model predictons and residuals. \n",
    "    '''\n",
    "    model = pm.auto_arima(np.array(data), seasonal=False, suppress_warnings=True, error_action=\"ignore\")\n",
    "    (p, d, q) = model.order\n",
    "    model = api.tsa.SARIMAX(data, order=(p, d, q))\n",
    "    model_fit = model.fit(disp=0, warn_convergence=False)\n",
    "    residuals = pd.DataFrame(model_fit.resid)\n",
    "    residuals[0][0] = 0\n",
    "    predict = model_fit.get_prediction()\n",
    "    predictions = pd.DataFrame(predict.predicted_mean)\n",
    "    predictions['predicted_mean'][0] = data['Value'][0]\n",
    "    return predictions, residuals\n",
    "\n",
    "# its completely unfeasible to do a hyperparameter tuning for every instance\n",
    "# at most lets try a few values for alpha, and maybe one or two values for window_sz\n",
    "# this is going to take so long, yikes\n",
    "def set_dynamic_threshold(residuals, window_sz=144, alpha=0.01, min_range=0.0):\n",
    "    \"\"\"\n",
    "    set_dynamic_threshold determines a threshold for each point based on the local confidence interval\n",
    "    considering the model residuals looking forward and backward a specified number of steps.\n",
    "    Arguments:\n",
    "        residuals: series like object or a data frame of model residuals.\n",
    "        alpha: scalar between 0 and 1 representing the acceptable uncertainty.\n",
    "        window_sz: integer representing how many data points to use in both directions.\n",
    "            default = 144 for one day for 10-minute data.\n",
    "    Returns:\n",
    "        threshold: data frame of columns of low and high threshold values.\n",
    "    \"\"\"\n",
    "    threshold = []  # initialize empty list to hold thresholds\n",
    "    z = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    # if the window size parameter is too big for this data set\n",
    "    if (window_sz > len(residuals)):\n",
    "        print(\"WARNING: in set_dynamic_threshold(), window_sz > len(data)! Reducing window_sz.\")\n",
    "        window_sz = len(residuals)  # reduce the window to the max allowable\n",
    "\n",
    "    # loop through data and add each threshold pair\n",
    "    for i in range(0, len(residuals)):\n",
    "        if (window_sz > i):  # index is closer than window size to left edge of data\n",
    "            lo = 0\n",
    "        else:  # look back as far as the window size\n",
    "            lo = i - window_sz\n",
    "        if (i + window_sz > len(residuals)):  # index is close to right edge of data\n",
    "            hi = len(residuals)\n",
    "        else:  # look forward as far as the window size\n",
    "            hi = i + window_sz\n",
    "\n",
    "        # calculate the range of probable values using given alpha\n",
    "        mean = np.mean(residuals[lo:(hi + 1)])[0]#.mean()\n",
    "        sigma = np.std(residuals[lo:(hi + 1)])[0]#.std()\n",
    "        th_range = z * sigma\n",
    "        if (th_range < min_range):\n",
    "            th_range = min_range\n",
    "        # append pair of upper and lower thresholds\n",
    "        threshold.append([mean - th_range, mean + th_range])\n",
    "\n",
    "    threshold = pd.DataFrame(threshold, columns=['low', 'high'])\n",
    "\n",
    "    return threshold\n",
    "\n",
    "def outlier_count(data, window_sz=144):\n",
    "    '''\n",
    "    Given a timeseries, fits an ARIMA model, determines dynamic thresholds and then identifies outliers. \n",
    "    Returns a count of how many outliers there are. \n",
    "    '''\n",
    "    predictions, residuals = get_arima_fit(data)\n",
    "    threshold = set_dynamic_threshold(residuals, window_sz=window_sz)\n",
    "    up_outliers = data[data['Value'] > predictions['predicted_mean'] + np.array(threshold['high'])]\n",
    "    down_outliers = data[data['Value'] < predictions['predicted_mean'] + np.array(threshold['low'])]\n",
    "    return len(up_outliers) + len(down_outliers)\n",
    "\n",
    "def count_arima_outliers(metadata, dataset='wl', window_sz=144):\n",
    "    '''\n",
    "    Uses an ARIMA model to detect anomalies and determine if a site is obstructed or not. \n",
    "    Arguments:\n",
    "        - metadata: the metadata file (see data/ folder for examples)\n",
    "        - dataset: 'wl', 'pH', or 'ec', used to specify which import and flagging functions should be used\n",
    "        - window_sz: integer representing how many data points to use in both directions.\n",
    "    '''\n",
    "    df = metadata.copy()\n",
    "    df['outlier count'] = np.zeros(len(df))\n",
    "    df['percent outlier'] = np.zeros(len(df))\n",
    "    \n",
    "    for row, col in df.iterrows():\n",
    "        if dataset == 'wl':\n",
    "            data = import_wl_data(node_id=col['Node ID'], site_id=col['Site ID'])\n",
    "            data = data[col['start']:col['end']]\n",
    "            offset = col['Offset (mm)']\n",
    "        elif dataset =='pH':\n",
    "            data = import_ph_data(col['node_id'], col['start'], col['end'])\n",
    "        elif dataset == 'ec':\n",
    "            data = import_ec_data(col['node_id'], col['start'], col['end'])\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            df['outlier count'].iloc[row] = len(data)\n",
    "        else:\n",
    "            if dataset == 'wl':\n",
    "                data, flag = flag_depth_errors(data, offset)\n",
    "            elif dataset == 'pH':\n",
    "                data, flag = flag_ph_errors(data)\n",
    "            elif dataset == 'ec':\n",
    "                data, flag = flag_ec_errors(data)\n",
    "                \n",
    "            if flag:\n",
    "                df['outlier count'].iloc[row] = len(data)\n",
    "            else:\n",
    "                df['outlier count'].iloc[row] = outlier_count(data[['Value']], window_sz=window_sz)\n",
    "        df['percent outlier'].iloc[row] = df['outlier count'].iloc[row] / len(data)\n",
    "        \n",
    "        if row % 10 ==0:\n",
    "            print(f\"row {row} finished processing\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93134e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runchecks_depth(metadata):\n",
    "    '''\n",
    "    Runs the rule-based tests for the water level dataset. \n",
    "    In this function, y_pred is 0 for all the flagged sites and 1 for all sites that were not flagged. \n",
    "    '''\n",
    "    df = metadata.copy()\n",
    "    df['flag'] = np.zeros(len(df))\n",
    "    \n",
    "    for row, col in df.iterrows():\n",
    "        data = import_wl_data(node_id=col['Node ID'], site_id=col['Site ID'])\n",
    "        data = data[col['start']:col['end']]\n",
    "        offset = col['Offset (mm)']\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            df['flag'].iloc[row] = 1\n",
    "        else:\n",
    "            data, flag = flag_depth_errors(data, offset) # this function needs to be specified to type of sensor\n",
    "            if flag:\n",
    "                df['flag'].iloc[row] = 1\n",
    "    y_pred = np.ones(len(df)) - df['flag']\n",
    "    \n",
    "    return y_pred, df['Clean']\n",
    "\n",
    "def runchecks_pH(metadata):\n",
    "    '''\n",
    "    Runs the rule-based tests for the pH dataset. \n",
    "    In this function, y_pred is 0 for all the flagged sites and 1 for all sites that were not flagged. \n",
    "    '''\n",
    "    df = metadata.copy()\n",
    "    df['flag'] = np.zeros(len(df))\n",
    "    \n",
    "    for row, col in df.iterrows():\n",
    "        data = import_ph_data(col['node_id'], col['start'], col['end'])\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            df['flag'].iloc[row] = 1\n",
    "        else:\n",
    "            data, flag = flag_ph_errors(data) # this function needs to be specified to type of sensor\n",
    "            if flag:\n",
    "                df['flag'].iloc[row] = 1\n",
    "    y_pred = np.ones(len(df)) - df['flag']\n",
    "    \n",
    "    return y_pred, df['clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb4671",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b42f5",
   "metadata": {},
   "source": [
    "## Water level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c158de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8387096774193549\n",
      "precision: 0.8211382113821138\n",
      "false positive rate: 0.11827956989247312\n"
     ]
    }
   ],
   "source": [
    "# classification on phase portraits for water level data \n",
    "y_pred, y = validate_depth(depth120d, nbins=[10,4], cv_k=5, dim=2, model='svm', scoring = 'accuracy')\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "717b12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8064516129032258\n",
      "precision: 0.7829457364341085\n",
      "false positive rate: 0.15053763440860216\n"
     ]
    }
   ],
   "source": [
    "# classification on value distribution for water level data \n",
    "y_pred, y = validate_depth(depth120d, nbins=10, cv_k=5, dim=1, model='svm', scoring = 'accuracy')\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7790f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7956989247311828\n",
      "precision: 0.7751937984496124\n",
      "false positive rate: 0.15591397849462366\n"
     ]
    }
   ],
   "source": [
    "# moving average for water level data \n",
    "windows = ['1D', '5D', '7D', '14D', '21D', '30D', '45D']\n",
    "pct_thrshs = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25]\n",
    "nstds = [2,3,4]\n",
    "acc = []\n",
    "for w in windows:\n",
    "    for p in pct_thrshs:\n",
    "        for n in nstds:\n",
    "            y_pred, y = rolling_mean_check(depth120d, dataset='wl', w=w, pct_thrsh=p, nstd=n)\n",
    "            C = confusion_matrix(y,y_pred)\n",
    "            accuracy = len(np.where(y_pred-y == 0)[0])/len(y)\n",
    "            acc.append({'window': w, 'pct': p, 'nstd': n, 'accuracy': accuracy, 'precision': C[1,1]/(C[1,1]+C[0,1])})\n",
    "acc_df = pd.DataFrame(acc)\n",
    "acc_df = acc_df.sort_values([\"accuracy\", \"precision\"])\n",
    "\n",
    "y_pred, y = rolling_mean_check(depth120d, dataset='wl', w=acc_df.iloc[-1]['window'], \n",
    "                                pct_thrsh=acc_df.iloc[-1]['pct'], nstd=acc_df.iloc[-1]['nstd'])\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3106c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 finished processing\n",
      "row 10 finished processing\n",
      "row 20 finished processing\n",
      "row 30 finished processing\n",
      "row 40 finished processing\n",
      "row 50 finished processing\n",
      "row 60 finished processing\n",
      "row 70 finished processing\n",
      "row 80 finished processing\n",
      "row 90 finished processing\n",
      "row 100 finished processing\n",
      "row 110 finished processing\n",
      "row 120 finished processing\n",
      "row 130 finished processing\n",
      "row 140 finished processing\n",
      "row 150 finished processing\n",
      "row 160 finished processing\n",
      "row 170 finished processing\n",
      "row 180 finished processing\n",
      "accuracy: 0.7634408602150538\n",
      "precision: 0.7152317880794702\n",
      "false positive rate: 0.23118279569892472\n"
     ]
    }
   ],
   "source": [
    "# ARIMA for water level data \n",
    "arima_120df = count_arima_outliers(depth120d, window_sz=288)\n",
    "lengths = []\n",
    "for row, col in depth120d.iterrows():\n",
    "    data = import_wl_data(node_id=col['Node ID'], site_id=col['Site ID'])\n",
    "    data = data[col['start']:col['end']]\n",
    "    lengths.append(len(data))\n",
    "arima_120df['percent outleirs'] = arima_120df['outlier count']/lengths\n",
    "pct_thrshs = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25]\n",
    "acc = []\n",
    "for p in pct_thrshs:\n",
    "    y_pred = [0 if i > p else 1 for i in arima_120df['percent outleirs']]\n",
    "    y = arima_120df['Clean']\n",
    "    C = confusion_matrix(y,y_pred)\n",
    "    accuracy = len(np.where(y_pred-y == 0)[0])/len(y)\n",
    "    acc.append({'pct': p, 'accuracy': accuracy, 'precision': C[1,1]/(C[1,1]+C[0,1])})\n",
    "acc_df = pd.DataFrame(acc)\n",
    "acc_df = acc_df.sort_values([\"accuracy\", \"precision\"])\n",
    "\n",
    "y_pred = [0 if i > acc_df.iloc[-1]['pct'] else 1 for i in arima_120df['percent outleirs']]\n",
    "y = arima_120df['Clean']\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06f92be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7688172043010753\n",
      "accuracy: 0.7688172043010753\n",
      "precision: 0.72\n",
      "false positive rate: 0.22580645161290322\n"
     ]
    }
   ],
   "source": [
    "# Rules-based tests for water level data\n",
    "y_pred, y = runchecks_depth(depth120d)\n",
    "print(len(np.where(y_pred-y == 0)[0])/len(y))\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f170469",
   "metadata": {},
   "source": [
    "## pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3e2441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "accuracy: 0.967741935483871\n",
      "precision: 0.9672131147540983\n",
      "false positive rate: 0.021505376344086023\n"
     ]
    }
   ],
   "source": [
    "# classification on phase portraits for pH data \n",
    "y_pred, y = validate_ph(pH_meta, nbins=[5, 4])\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11740e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "accuracy: 0.946236559139785\n",
      "precision: 0.9365079365079365\n",
      "false positive rate: 0.043010752688172046\n"
     ]
    }
   ],
   "source": [
    "# classification on value distribution for pH data \n",
    "y_pred, y = validate_ph(pH_meta, nbins=6, dim=1)\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57a0cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8387096774193549\n",
      "precision: 0.8082191780821918\n",
      "false positive rate: 0.15053763440860216\n"
     ]
    }
   ],
   "source": [
    "# moving average for pH data \n",
    "windows = ['1D', '5D', '7D', '14D', '21D', '30D', '45D']\n",
    "pct_thrshs = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25]\n",
    "nstds = [2,3,4]\n",
    "acc = []\n",
    "for w in windows:\n",
    "    for p in pct_thrshs:\n",
    "        for n in nstds:\n",
    "            y_pred, y = rolling_mean_check(pH_meta, dataset='pH', w=w, pct_thrsh=p, nstd=n)\n",
    "            C = confusion_matrix(y,y_pred)\n",
    "            accuracy = len(np.where(y_pred-y == 0)[0])/len(y)\n",
    "            acc.append({'window': w, 'pct': p, 'nstd': n, 'accuracy': accuracy, 'precision': C[1,1]/(C[1,1]+C[0,1])})\n",
    "            acc_df = pd.DataFrame(acc)\n",
    "            \n",
    "acc_df = acc_df.sort_values([\"accuracy\", \"precision\"])\n",
    "y_pred, y = rolling_mean_check(pH_meta, dataset='pH', w=acc_df.iloc[-1]['window'], \n",
    "                                pct_thrsh=acc_df.iloc[-1]['pct'], nstd=acc_df.iloc[-1]['nstd'])\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8597b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8279569892473119\n",
      "precision: 0.7894736842105263\n",
      "false positive rate: 0.17204301075268819\n"
     ]
    }
   ],
   "source": [
    "y_pred, y = runchecks_pH(pH_meta)\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5f1f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 finished processing\n",
      "row 10 finished processing\n",
      "row 20 finished processing\n",
      "row 30 finished processing\n",
      "row 40 finished processing\n",
      "row 50 finished processing\n",
      "row 60 finished processing\n",
      "row 70 finished processing\n",
      "row 80 finished processing\n",
      "row 90 finished processing\n",
      "accuracy: 0.8279569892473119\n",
      "precision: 0.8055555555555556\n",
      "false positive rate: 0.15053763440860216\n"
     ]
    }
   ],
   "source": [
    "arima_pH_df = count_arima_outliers(pH_meta, dataset='pH')\n",
    "pct_thrshs = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25]\n",
    "acc = []\n",
    "for p in pct_thrshs:\n",
    "    y_pred = [0 if i > p else 1 for i in arima_pH_df['percent outlier']]\n",
    "    y = arima_pH_df['clean']\n",
    "    C = confusion_matrix(y,y_pred)\n",
    "    accuracy = len(np.where(y_pred-y == 0)[0])/len(y)\n",
    "    acc.append({'pct': p, 'accuracy': accuracy, 'precision': C[1,1]/(C[1,1]+C[0,1])})\n",
    "acc_df = pd.DataFrame(acc)\n",
    "acc_df = acc_df.sort_values('accuracy')\n",
    "\n",
    "y_pred = [0 if i > acc_df.iloc[-1]['pct'] else 1 for i in arima_pH_df['percent outlier']]\n",
    "y = arima_pH_df['clean']\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a31e6",
   "metadata": {},
   "source": [
    "## EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e521d2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9615384615384616\n",
      "precision: 0.971830985915493\n",
      "false positive rate: 0.02564102564102564\n"
     ]
    }
   ],
   "source": [
    "# classification on phase portraits for ec data \n",
    "y_pred, y = validate_ec(ec_meta, nbins=[7,1])\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11b1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9615384615384616\n",
      "precision: 0.971830985915493\n",
      "false positive rate: 0.02564102564102564\n"
     ]
    }
   ],
   "source": [
    "# classification on value distribution for ec data \n",
    "y_pred, y = validate_ec(ec_meta, nbins=7, dim=1)\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2c6f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9102564102564102\n",
      "precision: 0.92\n",
      "false positive rate: 0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "# moving average for ec data \n",
    "windows = ['1D', '5D', '7D', '14D', '21D', '30D', '45D']\n",
    "pct_thrshs = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25]\n",
    "nstds = [2,3,4]\n",
    "acc = []\n",
    "for w in windows:\n",
    "    for p in pct_thrshs:\n",
    "        for n in nstds:\n",
    "            y_pred, y = rolling_mean_check(ec_meta, dataset='ec', w=w, pct_thrsh=p, nstd=n)\n",
    "            C = confusion_matrix(y,y_pred)\n",
    "            accuracy = len(np.where(y_pred-y == 0)[0])/len(y)\n",
    "            acc.append({'window': w, 'pct': p, 'nstd': n, 'accuracy': accuracy, 'precision': C[1,1]/(C[1,1]+C[0,1])})\n",
    "acc_df = pd.DataFrame(acc)\n",
    "acc_df = acc_df.sort_values([\"accuracy\", \"precision\"])\n",
    "y_pred, y = rolling_mean_check(ec_meta, dataset='ec', w=acc_df.iloc[-1]['window'], \n",
    "                                pct_thrsh=acc_df.iloc[-1]['pct'], nstd=acc_df.iloc[-1]['nstd'])\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dcc3b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 finished processing\n",
      "row 10 finished processing\n",
      "row 20 finished processing\n",
      "row 30 finished processing\n",
      "row 40 finished processing\n",
      "row 50 finished processing\n",
      "row 60 finished processing\n",
      "row 70 finished processing\n",
      "accuracy: 0.8974358974358975\n",
      "precision: 0.8974358974358975\n",
      "false positive rate: 0.10256410256410256\n"
     ]
    }
   ],
   "source": [
    "arima_ec_df = count_arima_outliers(ec_meta, dataset='ec')\n",
    "pct_thrshs = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25]\n",
    "acc = []\n",
    "for p in pct_thrshs:\n",
    "    y_pred = [0 if i > p else 1 for i in arima_ec_df['percent outlier']]\n",
    "    y = arima_ec_df['clean']\n",
    "    C = confusion_matrix(y,y_pred)\n",
    "    accuracy = len(np.where(y_pred-y == 0)[0])/len(y)\n",
    "    acc.append({'pct': p, 'accuracy': accuracy, 'precision': C[1,1]/(C[1,1]+C[0,1])})\n",
    "acc_df = pd.DataFrame(acc)\n",
    "acc_df = acc_df.sort_values('accuracy')\n",
    "\n",
    "y_pred = [0 if i > acc_df.iloc[-1]['pct'] else 1 for i in arima_ec_df['percent outlier']]\n",
    "y = arima_ec_df['clean']\n",
    "print('accuracy:', accuracy_score(y, y_pred))\n",
    "print('precision:', precision_score(y, y_pred))\n",
    "print('false positive rate:', confusion_matrix(y, y_pred)[0,1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd5f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
